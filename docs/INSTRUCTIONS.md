# Guide de Pr√©sentation en Classe

**Dur√©e recommand√©e:** 15-20 minutes
**Approche:** Dagster UI (interface visuelle professionnelle)

---

## Pr√©paration Avant la Pr√©sentation

### La Veille

```bash
# 1. V√©rifier Docker
docker ps

# 2. V√©rifier Python et just
python3 --version  # 3.9+
just --version

# 3. Setup complet
just setup

# 4. Test rapide Dagster
just dagster
# ‚Üí Ouvrir http://localhost:3000
# ‚Üí V√©rifier que l'interface charge

# 5. Nettoyer pour d√©mo fra√Æche
just clean
```

### Le Jour M√™me (30 min avant)

```bash
# Reset complet pour d√©mo propre
just clean
just setup

# Pr√©parer Dagster (ne pas fermer ce terminal)
just dagster

# ‚Üí http://localhost:3000 doit √™tre accessible
```

---

## Sc√©nario de Pr√©sentation (15 minutes)

### 1. Introduction (2 minutes)

**Ce que vous dites:**

> "Bonjour. Je vais vous pr√©senter notre syst√®me de d√©tection de fraude bancaire en temps r√©el. Ce syst√®me utilise les technologies Big Data √©tudi√©es en cours: Kafka pour le streaming, Spark pour le traitement distribu√©, MongoDB pour le stockage, et Machine Learning avec 3 mod√®les en ensemble pour la d√©tection."

**Montrez le sch√©ma d'architecture (README.md):**

```
Dataset Kaggle ‚Üí Producer ‚Üí Kafka ‚Üí Spark ‚Üí MongoDB ‚Üí Tableau
                               ‚Üì
                          SparkML (3 mod√®les)
```

**Points cl√©s √† mentionner:**
- 284K transactions Kaggle
- D√©tection en temps r√©el (<2 secondes)
- 3 mod√®les ML en ensemble (>99% accuracy)
- 4 collections MongoDB pour tra√ßabilit√©

---

### 2. D√©monstration Dagster UI (8 minutes)

#### A. Montrer l'Interface (1 min)

**Navigation:**
1. Ouvrez http://localhost:3000
2. Montrez l'interface principale

**Ce que vous dites:**

> "Nous utilisons Dagster, une plateforme d'orchestration moderne, pour g√©rer tout notre pipeline. Au lieu d'ex√©cuter des scripts manuellement, tout est orchestr√© visuellement avec des d√©pendances automatiques."

#### B. Expliquer les Assets (2 min)

**Navigation:**
1. Cliquez sur **"Assets"** (menu gauche)
2. Montrez le graphe de d√©pendances

**Ce que vous montrez:**

```
start_docker_services  ‚Üí  check_services  ‚Üí  accumulate_data  ‚Üí
train_models  ‚Üí  run_ml_predictions  ‚Üí  validate_data  ‚Üí  export_to_excel
```

**Ce que vous dites:**

> "Le pipeline se compose de 7 √©tapes automatis√©es:
> 1. **start_docker_services**: Lance Kafka, MongoDB, Spark automatiquement
> 2. **check_services**: V√©rifie que tout est pr√™t
> 3. **accumulate_data**: Collecte 2 minutes de transactions depuis Kafka
> 4. **train_models**: Entra√Æne nos 3 mod√®les ML en parall√®le
> 5. **run_ml_predictions**: Applique les mod√®les et fait du vote majoritaire
> 6. **validate_data**: V√©rifie la qualit√© (accuracy, pr√©cision)
> 7. **export_to_excel**: Exporte tout pour Tableau
>
> Dagster g√®re les d√©pendances: impossible d'entra√Æner sans donn√©es, impossible de pr√©dire sans mod√®les."

#### C. Lancer le Pipeline (5 min)

**Navigation:**
1. Cliquez sur **"Jobs"** (menu gauche)
2. Cliquez sur **"full_pipeline"**
3. Cliquez sur **"Launchpad"** (bouton en haut √† droite)
4. Cliquez sur **"Launch Run"**

**Ce que vous dites:**

> "Je vais maintenant lancer le pipeline complet avec un seul clic. Normalement √ßa prend 15-20 minutes, mais pour la d√©mo, chaque √©tape est acc√©l√©r√©e."

**Pendant l'ex√©cution:**

**~30 secondes:** start_docker_services
> "Dagster d√©marre automatiquement tous les services Docker. Plus besoin de le faire manuellement."

**~30 secondes:** check_services
> "V√©rification que Kafka, MongoDB, et Spark sont bien d√©marr√©s."

**~2 minutes:** accumulate_data
> "Collecte de transactions. Dans une vraie utilisation, on laisserait tourner plus longtemps pour avoir plus de donn√©es."

**~10-15 minutes:** train_models (si le temps le permet, sinon passez)
> "Entra√Ænement des 3 mod√®les. C'est la partie la plus longue. Vous pouvez voir les logs en temps r√©el ici..."

**(Optionnel) Si le training prend trop de temps:**
- Cliquez sur l'asset en cours
- Montrez les logs qui d√©filent
- Expliquez que c'est normal et qu'on va utiliser des mod√®les pr√©-entra√Æn√©s

**Astuce:** Si vous avez peu de temps, utilisez le job "validate_data" seul au lieu de "full_pipeline" pour montrer rapidement Dagster.

---

### 3. Machine Learning - Approche Ensemble (2 minutes)

**Pendant que le training tourne ou apr√®s:**

**Ce que vous dites:**

> "Notre approche ML utilise 3 mod√®les compl√©mentaires:
>
> **1. Random Forest**: Robuste, capture les interactions non-lin√©aires
> **2. Gradient Boosting**: Excellent sur donn√©es d√©s√©quilibr√©es (0.17% de fraudes)
> **3. Logistic Regression**: Baseline interpr√©table
>
> **Vote Majoritaire**: Pour chaque transaction, on fait voter les 3 mod√®les. La d√©cision finale est le consensus (2/3 ou 3/3). √áa nous donne plus de 99% d'accuracy.
>
> **Auto-Flagging**: Si les 3 mod√®les sont unanimes OU si la probabilit√© moyenne d√©passe 80%, on flag automatiquement la transaction pour action imm√©diate."

**Montrez le README.md - section ensemble code:**

```python
# D√©cision finale
final_prediction = majority_vote(vote_rf, vote_gb, vote_lr)
confidence = average(prob_rf, prob_gb, prob_lr)

# Auto-flagging
if confidence > 0.80 or (vote_rf == vote_gb == vote_lr == 1):
    flag_transaction(transaction)
```

---

### 4. Base de Donn√©es et R√©sultats (2 minutes)

#### A. MongoDB - 4 Collections (1 min)

**Navigation:**
- Ouvrez http://localhost:8081 (Mongo Express)
- Naviguez dans les 4 collections

**Ce que vous montrez:**

1. **transactions**: Donn√©es brutes (Time, V1-V28, Amount, Class)
2. **model_predictions**: Pr√©diction de chaque mod√®le individuellement
3. **ensemble_results**: D√©cision finale + vote + confiance
4. **flagged_transactions**: Cas critiques auto-flagg√©s

**Ce que vous dites:**

> "On utilise 4 collections MongoDB pour la tra√ßabilit√© compl√®te:
> - **transactions**: Toutes les donn√©es brutes
> - **model_predictions**: Chaque mod√®le garde sa pr√©diction (audit)
> - **ensemble_results**: La d√©cision finale avec le vote et la confiance
> - **flagged_transactions**: Les cas √† haut risque isol√©s pour action imm√©diate
>
> Cette structure permet l'audit complet et l'analyse de performance de chaque mod√®le."

#### B. Export Excel pour Tableau (1 min)

**Navigation:**
- Retournez √† Dagster UI
- Montrez l'asset "export_to_excel" compl√©t√©
- Ouvrez le dossier `exports/` dans Finder/Explorer

**Ce que vous montrez:**
- `transactions.xlsx`
- `model_predictions.xlsx`
- `ensemble_results.xlsx`
- `flagged_transactions.xlsx`

**Ce que vous dites:**

> "Tout est automatiquement export√© en Excel pour Tableau. Quatre fichiers pour cr√©er des dashboards: analyse temporelle, comparaison des mod√®les, distribution des fraudes, transactions flagg√©es. Voir le document CHARTS.md pour les visualisations recommand√©es."

---

### 5. D√©cisions Business (1 minute)

**Ce que vous dites:**

> "Ce syst√®me supporte plusieurs d√©cisions business:
>
> **1. Blocage Temps R√©el**: Transaction flagg√©e ‚Üí carte bloqu√©e imm√©diatement ‚Üí r√©duction des pertes
>
> **2. Analyse des Patterns**: Identifier nouvelles techniques de fraude, heures/montants √† risque
>
> **3. Optimisation Continue**: Comparer les 3 mod√®les, ajuster les seuils, r√©entra√Æner avec nouvelles donn√©es
>
> **4. Conformit√©**: Historique complet dans MongoDB pour audit, chaque d√©cision est tra√ßable
>
> Latence bout-en-bout: moins de 2 secondes. Scalable horizontalement via Kafka et Spark."

---

### 6. Questions & R√©ponses

**Questions fr√©quentes:**

**Q: Pourquoi 3 mod√®les au lieu d'un seul?**
> R: Robustesse. Un mod√®le peut se tromper. Trois mod√®les d'accord = haute confiance. √áa r√©duit les faux positifs qui co√ªtent cher (blocage carte client l√©gitime).

**Q: Pourquoi Kafka et pas directement fichier CSV?**
> R: Kafka permet le streaming temps r√©el. En production, les transactions arrivent en continu. On veut d√©tecter imm√©diatement, pas attendre un batch.

**Q: Pourquoi MongoDB et pas SQL?**
> R: NoSQL est flexible (sch√©ma peut √©voluer), performant sur requ√™tes fraud sp√©cifiques, et excellent pour agr√©gations analytics.

**Q: Comment vous g√©rez le d√©s√©quilibre (0.17% fraudes)?**
> R: Gradient Boosting est sp√©cialis√© pour √ßa. On utilise aussi AUC-ROC (pas juste accuracy) et on peut ajuster les class weights.

**Q: Dagster vs scripts?**
> R: Scripts = manuel, erreur-prone, pas de visibilit√©. Dagster = reproductible, d√©pendances auto, logs centralis√©s, m√©tadonn√©es riches.

---

## D√©pannage Express

### Dagster ne d√©marre pas

```bash
# Tuer processus sur port 3000
lsof -i :3000
kill -9 <PID>

# Relancer
just dagster
```

### Services Docker ne d√©marrent pas

```bash
just stop
just start
just health
```

### Pipeline bloqu√©

```bash
# Dans Dagster UI: Terminer le run
# Puis:
just clean-checkpoint
# Relancer le job
```

### Pas de donn√©es dans MongoDB

```bash
# V√©rifier producer
docker logs producer --tail 20

# Red√©marrer si n√©cessaire
just restart
```

---

## Plan B (Si Tout √âchoue)

**Avoir pr√©par√© avant:**
1. Screenshots de Dagster UI avec pipeline complet
2. Fichiers Excel dans exports/ (pr√©-g√©n√©r√©s)
3. Captures MongoDB avec les 4 collections
4. Screenshots de m√©triques (accuracy >99%)

**Pr√©sentation alternative:**
- Montrez les captures d'√©cran
- Expliquez l'architecture avec le sch√©ma
- Ouvrez le code source (producer.py, train_model.py) pour montrer la technique
- Expliquez comment √ßa fonctionne conceptuellement

---

## Checklist Finale

**Avant de commencer:**
- [ ] Docker Desktop est lanc√©
- [ ] `just health` ‚Üí tout est vert
- [ ] Dagster UI accessible (http://localhost:3000)
- [ ] Mongo Express accessible (http://localhost:8081)
- [ ] README.md ouvert pour sch√©ma architecture
- [ ] CHARTS.md disponible si questions sur Tableau
- [ ] √âcran partag√© / projet√© correctement

**Timing:**
- [ ] Introduction: 2 min
- [ ] Dagster d√©mo: 8 min (dont 5 min ex√©cution)
- [ ] ML ensemble: 2 min
- [ ] MongoDB + Export: 2 min
- [ ] Business decisions: 1 min
- [ ] Questions: reste du temps

**Talking points m√©moris√©s:**
- [ ] 284K transactions, 0.17% fraudes
- [ ] 3 mod√®les, vote majoritaire, >99% accuracy
- [ ] 4 collections MongoDB pour tra√ßabilit√©
- [ ] <2 secondes latence bout-en-bout
- [ ] Scalable (Kafka partitions, Spark cluster)

---

**üéì Bonne pr√©sentation!**
