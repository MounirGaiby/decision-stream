# Instructions pour la Pr√©sentation en Classe

Ce guide fournit des instructions d√©taill√©es pour pr√©senter le syst√®me de d√©tection de fraude en classe.

---

## üìã Table des Mati√®res

1. [Pr√©paration Avant la Pr√©sentation](#pr√©paration-avant-la-pr√©sentation)
2. [M√©thode Recommand√©e: Dagster UI](#m√©thode-recommand√©e-dagster-ui)
3. [M√©thode Alternative: Scripts Manuels](#m√©thode-alternative-scripts-manuels)
4. [Sc√©nario de Pr√©sentation (20 minutes)](#sc√©nario-de-pr√©sentation-20-minutes)
5. [Points Cl√©s √† Mentionner](#points-cl√©s-√†-mentionner)
6. [D√©pannage Pendant la Pr√©sentation](#d√©pannage-pendant-la-pr√©sentation)

---

## Pr√©paration Avant la Pr√©sentation

### V√©rifications Pr√©alables (√Ä Faire 1 Jour Avant)

```bash
# 1. V√©rifier Docker
docker ps

# 2. V√©rifier l'environnement virtuel Python
source venv/bin/activate
python --version  # Doit √™tre Python 3.9+

# 3. V√©rifier just est install√©
just --version

# 4. V√©rifier Dagster
source venv/bin/activate
dagster --version

# 5. Configuration initiale (si premi√®re fois)
just setup
```

### Nettoyage et Reset (Le Jour de la Pr√©sentation)

```bash
# Nettoyer toutes les donn√©es pour repartir de z√©ro
just clean

# Red√©marrer les services
just start

# V√©rifier que tout fonctionne
just health
```

---

## M√©thode Recommand√©e: Dagster UI

### Pourquoi Dagster?

**Avantages pour la pr√©sentation:**
- ‚úÖ Interface visuelle professionnelle
- ‚úÖ Progression en temps r√©el visible par l'audience
- ‚úÖ Logs centralis√©s et organis√©s
- ‚úÖ Ex√©cution simplifi√©e (un clic)
- ‚úÖ M√©triques et m√©tadonn√©es automatiques
- ‚úÖ Gestion des d√©pendances automatique

### Workflow avec Dagster

#### 1. D√©marrer Dagster UI

```bash
# Terminal 1: Lancer Dagster
just dagster

# Ouvrir dans le navigateur
# http://localhost:3000
```

**Ce que vous verrez:**
- Interface Dagster avec menu de gauche
- Tabs: Assets, Jobs, Runs, Overview

#### 2. Montrer l'Architecture (Assets)

1. Cliquez sur **"Assets"** dans le menu gauche
2. Montrez le graphe de d√©pendances:
   ```
   check_services ‚Üí accumulate_data ‚Üí train_models ‚Üí
   run_ml_predictions ‚Üí validate_data ‚Üí export_to_excel
   ```
3. Expliquez chaque asset bri√®vement (voir section "Points Cl√©s")

#### 3. Ex√©cuter le Pipeline Complet

1. Cliquez sur **"Jobs"** dans le menu gauche
2. S√©lectionnez **"full_pipeline"**
3. Cliquez sur **"Launchpad"** (bouton en haut √† droite)
4. Cliquez sur **"Launch Run"**

**Pendant l'ex√©cution:**
- Montrez la progression en temps r√©el
- Cliquez sur chaque asset pour voir les logs
- Expliquez ce qui se passe √† chaque √©tape
- Montrez les m√©tadonn√©es (nombre de transactions, accuracy, etc.)

#### 4. Voir les R√©sultats

Une fois le pipeline termin√©:
1. Cliquez sur **"validate_data"** asset
2. Montrez les m√©triques de qualit√©
3. Expliquez les r√©sultats (accuracy, precision, recall)

#### 5. Ouvrir les Donn√©es Export√©es

```bash
# Les fichiers Excel sont dans exports/
ls -lh exports/

# Montrer un fichier
open exports/ensemble_results.xlsx  # macOS
```

### Jobs Individuels (Si Besoin)

Si vous voulez montrer des √©tapes individuelles:

```bash
# Via commandes
just dagster-accumulate   # Accumulation seulement
just dagster-train        # Entra√Ænement seulement
just dagster-predict      # Pr√©dictions seulement

# Ou via UI:
# Jobs ‚Üí S√©lectionner le job ‚Üí Launch Run
```

---

## M√©thode Alternative: Scripts Manuels

Si Dagster ne fonctionne pas ou si vous pr√©f√©rez montrer le processus manuel.

### Workflow Manuel (Pas √† Pas)

#### 1. Setup Initial

```bash
# D√©marrer tous les services
just start

# V√©rifier l'√©tat
just status
```

#### 2. Accumulation de Donn√©es (5-10 minutes)

```bash
# Terminal 1: D√©marrer l'accumulation
just run-basic

# Terminal 2: Surveiller la progression
just check
```

**Pendant l'accumulation:**
- Montrez les logs Spark qui d√©filent
- Ex√©cutez `just check` r√©guli√®rement pour voir les compteurs augmenter
- Expliquez: "On collecte des transactions depuis Kafka, on les traite avec Spark, et on les stocke dans MongoDB"
- Objectif: Accumuler ~5000+ transactions (minimum 100)

**Arr√™t:**
- Pressez `Ctrl+C` dans le terminal qui ex√©cute `just run-basic`

#### 3. Entra√Ænement des Mod√®les (10-15 minutes)

```bash
# Entra√Æner les 3 mod√®les
just train
```

**Pendant l'entra√Ænement:**
- Montrez les logs de progression
- Expliquez les 3 mod√®les: Random Forest, Gradient Boosting, Logistic Regression
- Montrez les m√©triques finales (AUC-ROC, Accuracy, Precision, Recall)

**V√©rification:**
```bash
just check-model  # Confirme que les 3 mod√®les existent
```

#### 4. Pr√©dictions avec ML (2-5 minutes)

```bash
# Terminal 1: D√©marrer les pr√©dictions
just run-ml

# Terminal 2: V√©rifier les pr√©dictions
just check-ml
```

**Pendant les pr√©dictions:**
- Montrez les logs avec les pr√©dictions en temps r√©el
- Ex√©cutez `just check-ml` pour voir les statistiques
- Expliquez l'ensemble voting (vote majoritaire des 3 mod√®les)
- Montrez les transactions flagg√©es (high-risk)

#### 5. Export pour Tableau

```bash
just export-excel
```

Montrez les fichiers Excel cr√©√©s dans `exports/`:
- `transactions.xlsx`
- `model_predictions.xlsx`
- `ensemble_results.xlsx`
- `flagged_transactions.xlsx`

---

## Sc√©nario de Pr√©sentation (20 minutes)

### Introduction (2 minutes)

"Bonjour, je vais vous pr√©senter notre syst√®me de d√©tection de fraude bancaire en temps r√©el. Ce syst√®me utilise les technologies Big Data que nous avons √©tudi√©es: Kafka pour le streaming, Spark pour le traitement, MongoDB pour le stockage, et Machine Learning pour la d√©tection."

**Montrez le sch√©ma d'architecture:**
```
Dataset Kaggle ‚Üí Producer ‚Üí Kafka ‚Üí Spark Streaming ‚Üí MongoDB ‚Üí Tableau
                                        ‚Üì
                                   SparkML (3 Models)
```

### D√©monstration de l'Architecture (3 minutes)

**Montrez les services Docker:**
```bash
just status
```

Expliquez chaque service:
- **Kafka**: Message broker pour le streaming temps r√©el
- **MongoDB**: Base de donn√©es NoSQL pour persistance
- **Spark**: Moteur de traitement distribu√©
- **Producer**: G√©n√®re des transactions depuis le dataset Kaggle
- **Monitoring**: Mongo Express (visualiser les donn√©es), Dozzle (logs)

**Ouvrez les interfaces web:**
```bash
# Mongo Express (donn√©es)
open http://localhost:8081

# Dozzle (logs)
open http://localhost:8080
```

### Option A: D√©monstration avec Dagster (10 minutes)

**1. Lancer Dagster (1 min)**
```bash
just dagster
# Ouvrir http://localhost:3000
```

**2. Montrer les Assets (2 min)**
- Cliquez sur "Assets"
- Expliquez le graphe de d√©pendances
- D√©crivez bri√®vement chaque asset

**3. Lancer le Pipeline (5 min)**
- Jobs ‚Üí full_pipeline ‚Üí Launch Run
- Montrez la progression en temps r√©el
- Cliquez sur les assets pour voir les logs
- Expliquez ce qui se passe √† chaque √©tape

**4. Voir les R√©sultats (2 min)**
- Montrez les m√©triques finales
- Ouvrez les fichiers Excel export√©s
- Expliquez comment les utiliser dans Tableau

### Option B: D√©monstration Manuelle (10 minutes)

**1. Accumulation (3 min)**
```bash
just run-basic
# Dans un autre terminal: just check
```
- Montrez les logs
- Expliquez le flux: Kafka ‚Üí Spark ‚Üí MongoDB
- Montrez les compteurs qui augmentent

**2. Entra√Ænement (3 min)**
```bash
just train
```
- Expliquez les 3 mod√®les
- Montrez les m√©triques (accuracy >99%)
- Expliquez l'ensemble approach

**3. Pr√©dictions (3 min)**
```bash
just run-ml
# Dans un autre terminal: just check-ml
```
- Montrez les pr√©dictions en temps r√©el
- Expliquez le vote majoritaire
- Montrez les transactions flagg√©es

**4. Export (1 min)**
```bash
just export-excel
open exports/
```

### Machine Learning en D√©tail (3 minutes)

Expliquez l'approche ensemble:

**3 Mod√®les Compl√©mentaires:**
1. **Random Forest**: Robuste, g√®re bien les features non-lin√©aires
2. **Gradient Boosting**: Excellent pour les d√©s√©quilibres de classes
3. **Logistic Regression**: Baseline, interpr√©table

**Vote Majoritaire:**
- Chaque mod√®le vote: fraude ou normal
- D√©cision finale: majorit√© (2/3 ou 3/3)
- Confiance: moyenne des probabilit√©s

**Auto-flagging:**
- Transaction flagg√©e si:
  - Tous les mod√®les sont d'accord (unanimit√©), OU
  - Probabilit√© moyenne > 80%
- Permet l'action imm√©diate sur les cas √©vidents

### Structure de la Base de Donn√©es (2 minutes)

Montrez MongoDB avec Mongo Express:

**4 Collections:**
1. **transactions**: Toutes les transactions brutes
2. **model_predictions**: Pr√©dictions individuelles de chaque mod√®le
3. **ensemble_results**: D√©cisions finales (vote majoritaire)
4. **flagged_transactions**: Cas √† haut risque (auto-flagged)

Montrez des exemples de documents dans chaque collection.

### Questions et R√©ponses (variable)

---

## Points Cl√©s √† Mentionner

### Architecture Big Data

**Pourquoi Kafka?**
- Streaming en temps r√©el (pas de batch)
- Haute disponibilit√© et scalabilit√©
- D√©couplage producer/consumer

**Pourquoi Spark?**
- Traitement distribu√© (scale horizontalement)
- Micro-batches (optimise latence vs throughput)
- SparkML int√©gr√© (pas besoin d'exporter les donn√©es)

**Pourquoi MongoDB?**
- NoSQL: sch√©ma flexible pour √©volution future
- Performance: index optimis√©s pour requ√™tes fraud
- Agr√©gations puissantes pour analytics

### Machine Learning

**Dataset:**
- 284,807 transactions Kaggle
- 492 fraudes (0.172% - tr√®s d√©s√©quilibr√©!)
- 28 features PCA (V1-V28) + Amount + Time

**D√©fis:**
- Classe tr√®s d√©s√©quilibr√©e (99.8% normal, 0.2% fraude)
- Temps r√©el requis (<100ms par transaction)
- Faux positifs co√ªteux (blocage carte client)
- Faux n√©gatifs catastrophiques (perte financi√®re)

**Solution: Ensemble de 3 mod√®les**
- Meilleure robustesse que mod√®le unique
- R√©duit les faux positifs (unanimit√© requise)
- Haute accuracy (>99%) avec recall √©lev√©

### Performance

**Throughput:**
- Producer: ~10 transactions/seconde
- Spark: traite microbatch de 50-100 trans en <1s
- MongoDB: √©crit ~1000+ trans/minute

**Latence:**
- Bout en bout: <2 secondes (Kafka ‚Üí Spark ‚Üí MongoDB)
- Pr√©diction ML: ~50ms par microbatch

**Scalabilit√©:**
- Kafka: partitionnement horizontal
- Spark: cluster multi-n≈ìuds (actuellement 1 n≈ìud local)
- MongoDB: sharding possible

### D√©cisions Business

**Ce syst√®me permet de:**
1. **Bloquer transactions suspectes en temps r√©el**
   - Si flagged=true: bloquer imm√©diatement
   - R√©duire pertes financi√®res

2. **Analyser patterns de fraude**
   - Tableau dashboards pour trends
   - Identifier nouvelles techniques de fraude

3. **Optimiser r√®gles m√©tier**
   - Ajuster seuils de probabilit√©
   - Balance faux positifs vs faux n√©gatifs

4. **Audit et conformit√©**
   - Historique complet dans MongoDB
   - Tra√ßabilit√© de chaque d√©cision

---

## D√©pannage Pendant la Pr√©sentation

### Probl√®me: Services Docker ne d√©marrent pas

```bash
# V√©rifier Docker Desktop est lanc√©
docker ps

# Si rien, red√©marrer tout
just restart

# Si erreur persistante
just clean
just start
```

### Probl√®me: Pas de donn√©es dans MongoDB

```bash
# V√©rifier le producer tourne
docker logs producer --tail 20

# V√©rifier Spark tourne
docker logs spark --tail 20

# Red√©marrer l'accumulation
just clean-checkpoint
just run-basic
```

### Probl√®me: Mod√®les ne se chargent pas

```bash
# V√©rifier les mod√®les existent
just check-model

# Si manquants, r√©entra√Æner
just clean-model
just train
```

### Probl√®me: Dagster ne d√©marre pas

```bash
# V√©rifier port 3000 libre
lsof -i :3000

# Si occup√©, tuer le processus
kill -9 <PID>

# Ou utiliser un autre port
export DAGSTER_PORT=3001
dagster-webserver -h 0.0.0.0 -p 3001 -w workspace.yaml
```

### Probl√®me: Performances lentes

```bash
# V√©rifier ressources syst√®me
docker stats

# Augmenter m√©moire Spark (dans docker-compose.yml)
# SPARK_WORKER_MEMORY=4g

# Red√©marrer
just restart
```

### Plan B: Si Tout √âchoue

**Montrer des r√©sultats pr√©-g√©n√©r√©s:**
1. Ouvrez les fichiers Excel dans `exports/`
2. Montrez des captures d'√©cran de Dagster UI
3. Expliquez l'architecture avec le sch√©ma
4. Montrez le code source des composants cl√©s

**Fichiers √† pr√©parer √† l'avance:**
- Screenshots de Dagster UI avec pipeline complet
- Excel avec donn√©es r√©elles export√©es
- Logs exemple de Spark avec pr√©dictions
- Captures MongoDB avec les 4 collections

---

## Commandes de R√©f√©rence Rapide

```bash
# Setup et d√©marrage
just setup              # Configuration compl√®te initiale
just start              # D√©marrer services
just status             # V√©rifier √©tat services

# Dagster (Recommand√©)
just dagster            # Lancer UI Dagster
just dagster-full       # Pipeline complet via CLI
just dagster-accumulate # Accumulation seulement
just dagster-train      # Entra√Ænement seulement
just dagster-predict    # Pr√©dictions seulement

# M√©thode manuelle (Alternative)
just run-basic          # Accumulation donn√©es
just train              # Entra√Æner mod√®les
just run-ml             # Pr√©dictions ML
just export-excel       # Export pour Tableau

# Monitoring
just check              # Statistiques MongoDB
just check-ml           # Statistiques ML
just check-model        # V√©rifier mod√®les
just health             # Sant√© syst√®me compl√®te
just logs               # Logs tous services

# Nettoyage
just clean              # Tout nettoyer (reset complet)
just clean-model        # Supprimer mod√®les seulement
just clean-checkpoint   # Fixer streams bloqu√©s
just stop               # Arr√™ter services

# Interfaces web
open http://localhost:3000  # Dagster UI
open http://localhost:8081  # Mongo Express (donn√©es)
open http://localhost:8080  # Dozzle (logs)
```

---

## Documentation Additionnelle

Pour plus de d√©tails pendant la pr√©paration:

| Document | Utilit√© |
|----------|---------|
| [DAGSTER.md](DAGSTER.md) | Guide complet Dagster (assets, jobs, troubleshooting) |
| [DATABASE_STRUCTURE.md](DATABASE_STRUCTURE.md) | Sch√©ma MongoDB, exemples de documents |
| [TABLEAU_GUIDE.md](TABLEAU_GUIDE.md) | Cr√©er visualisations Tableau |
| [BENCHMARK.md](BENCHMARK.md) | M√©triques de performance d√©taill√©es |
| [COMMANDS.md](COMMANDS.md) | R√©f√©rence compl√®te des commandes |
| [README.md](../README.md) | Vue d'ensemble du projet |

---

**Bonne pr√©sentation! üéì**
