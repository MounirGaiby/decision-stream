# üîç Syst√®me de D√©tection de Fraude en Temps R√©el

Projet r√©alis√© dans le cadre du module **Processus D√©cisionnel Big Data**.

Syst√®me complet de d√©tection de fraude bancaire utilisant Machine Learning et traitement en temps r√©el.

---

## üìä Architecture Compl√®te

```
Dataset Kaggle
    ‚Üì
Producer (Python) ‚Üí Kafka ‚Üí Spark Streaming ‚Üí MongoDB ‚Üí Tableau
                                ‚Üì
                         SparkML (Random Forest)
                                ‚Üì
                    Pr√©dictions temps r√©el
```

### Composants du Syst√®me

| Composant | Technologie | R√¥le |
|-----------|-------------|------|
| **Ingestion** | Kafka | Streaming des transactions en temps r√©el |
| **Traitement** | Spark Streaming | Traitement et transformation des donn√©es |
| **ML** | SparkML (Random Forest) | D√©tection de fraude par Machine Learning |
| **Stockage** | MongoDB | Base de donn√©es NoSQL pour persistance |
| **Visualisation** | Tableau | Dashboards et analyses visuelles |
| **Monitoring** | Dozzle, Mongo Express | Surveillance syst√®me et donn√©es |

---

## üöÄ Installation et D√©marrage

### Pr√©requis

- Docker Desktop install√© et d√©marr√©
- Python 3.9+ install√©
- Compte Kaggle (pour le dataset)

### √âtape 1 : Configuration Kaggle

1. Cr√©ez un compte sur [Kaggle](https://www.kaggle.com)
2. Allez dans Settings ‚Üí API ‚Üí Create New API Token
3. Notez votre token (format : `KGAT_xxxxx...`)
4. Cr√©ez un fichier `.env` √† la racine :

```env
KAGGLE_API_TOKEN=KGAT_votre_token_ici
KAFKA_BOOTSTRAP_SERVERS=kafka:29092
KAFKA_TOPIC=fraud-detection-stream
STATE_FILE=/app/state/producer_state.db
```

### √âtape 2 : D√©marrage de l'Infrastructure

```powershell
# D√©marrer tous les services Docker
docker-compose up -d

# V√©rifier que tous les containers sont UP (6 containers)
docker ps
```

**Services disponibles :**
- Kafka : `localhost:9092`
- MongoDB : `localhost:27017`
- Mongo Express : `http://localhost:8081`
- Dozzle (logs) : `http://localhost:8080`

### √âtape 3 : Installation des D√©pendances Python (Spark)

```powershell
# Installer numpy, pandas, scikit-learn dans le container Spark
.\setup-spark-dependencies.ps1
```

**Dur√©e :** 3-5 minutes


## üîÑ Workflow Complet

### Phase 1 : Traitement Sans ML (Accumulation de donn√©es)

```powershell
# avec PowerShell
.\start-spark-processor.ps1
```

**Laisser tourner 5-10 minutes** pour accumuler ~5000 transactions.

**V√©rification :**
```powershell
python check_mongodb.py
```

### Phase 2 : Entra√Ænement du Mod√®le ML

```powershell
# 1. Arr√™ter le processeur Spark (Ctrl+C dans le terminal)

# 2. Entra√Æner le mod√®le Random Forest
.\train-model.ps1
```

**Dur√©e :** 5-10 minutes

**R√©sultat attendu :**
```
üìà Dataset Statistics:
   Total transactions: 5000+
   Normal transactions: 4990+ (99.X%)
   Fraudulent transactions: 10+ (0.X%)

üå≤ Training Random Forest...
   ‚úÖ Model trained successfully!

üìà MODEL PERFORMANCE METRICS
   AUC-ROC:   0.98+
   Accuracy:  0.99+
   Precision: 0.99+
   Recall:    0.99+
   F1-Score:  0.99+

üíæ Model saved to: /app/models/fraud_detection_model
```

### Phase 3 : Pr√©dictions en Temps R√©el

```powershell
# D√©marrer le processeur Spark avec ML
.\start-spark-ml.ps1
```

**Le syst√®me va maintenant :**
- Lire les transactions depuis Kafka
- Faire des pr√©dictions en temps r√©el
- Ajouter `fraud_prediction` et `fraud_probability` dans MongoDB

**V√©rification des pr√©dictions :**
```powershell
python check_ml_predictions.py
```

**R√©sultat attendu :**
```
ü§ñ ML PREDICTIONS - MongoDB Statistics
================================
üìà Total transactions: 7000+
ü§ñ Transactions with ML predictions: 3500+

üìà Model Performance:
   Accuracy: 99.X%
   Precision: 100.00%
   Recall: 100.00%

üìä Confusion Matrix:
   True Positives (Fraud detected): X
   False Positives (False alarm): X
   True Negatives (Normal detected): X
   False Negatives (Fraud missed): X
```


## üìä Dataset

**Credit Card Fraud Detection** (Kaggle)
- Source : [Kaggle Dataset](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- 284,807 transactions
- 492 fraudes (0.172%)
- 31 features : Time, V1-V28 (PCA), Amount, Class

### Sch√©ma des Donn√©es

**Dans Kafka/MongoDB :**
```json
{
  "Time": 0.0,
  "V1": -1.359807,
  "V2": -0.072781,
  ...
  "V28": -0.021053,
  "Amount": 149.62,
  "Class": 0.0,
  "processed_at": "2026-01-09T14:30:45.123Z"
}
```

**Avec Pr√©dictions ML :**
```json
{
  "Time": 0.0,
  "V1": -1.359807,
  ...
  "Amount": 149.62,
  "Class": 0.0,
  "fraud_prediction": 0,
  "fraud_probability": 0.02,
  "processed_at": "2026-01-09T14:30:45.123Z"
}
```

---

## ü§ñ Machine Learning

### Algorithme : Random Forest Classifier

**Configuration :**
- Nombre d'arbres : 100
- Profondeur maximale : 10
- Features : V1-V28 + Amount (29 features)
- Normalisation : StandardScaler
- Split : 80% train / 20% test

### M√©triques de Performance

**R√©sultats typiques :**
- **AUC-ROC :** 0.98+ (excellente s√©paration des classes)
- **Accuracy :** 99%+ (tr√®s peu d'erreurs)
- **Precision :** 80-100% (peu de fausses alertes)
- **Recall :** 80-100% (peu de fraudes manqu√©es)
- **F1-Score :** 0.99+ (bon √©quilibre)

### Feature Importance

Les 10 features les plus importantes (typiquement) :
1. V14, V12, V10 (composantes PCA li√©es au comportement)
2. Amount (montant de la transaction)
3. V17, V16, V18
4. Time (moment de la transaction)

---

## üìà Monitoring et V√©rification

### Interfaces Web

| Interface | URL | Description |
|-----------|-----|-------------|
| Dozzle | `http://localhost:8080` | Logs Docker en temps r√©el |
| Mongo Express | `http://localhost:8081` | Interface MongoDB |

### Scripts de V√©rification

```powershell
# V√©rifier les donn√©es dans MongoDB
python check_mongodb.py

# V√©rifier les pr√©dictions ML
python check_ml_predictions.py

# Voir les logs
docker logs producer --tail 50
docker logs spark --tail 50
docker logs mongodb --tail 50
```

---

## üéØ √âtat du Projet

| Composant | √âtat | Notes |
|-----------|------|-------|
| ‚úÖ Ingestion (Kafka) | **Complet** | Producer avec √©tat persistant |
| ‚úÖ Stockage (MongoDB) | **Complet** | Base NoSQL + interface web |
| ‚úÖ Traitement (Spark Streaming) | **Complet** | Traitement temps r√©el |
| ‚úÖ Machine Learning (SparkML) | **Complet** | Random Forest 99%+ accuracy |
| ‚è≥ Visualisation (Tableau) | **√Ä faire** | Prochaine √©tape |

---