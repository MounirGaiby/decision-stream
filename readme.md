# üîç Syst√®me de D√©tection de Fraude en Temps R√©el

Projet r√©alis√© dans le cadre du module **Processus D√©cisionnel Big Data**.

Syst√®me complet de d√©tection de fraude bancaire utilisant Machine Learning et traitement en temps r√©el.

## üñ•Ô∏è Support Multi-Plateforme

Ce projet fonctionne sur **Windows**, **macOS** et **Linux** :
- Scripts PowerShell (`.ps1`) pour Windows
- Scripts Bash (`.sh`) pour macOS et Linux
- Tous les scripts Docker et Python fonctionnent de mani√®re identique sur toutes les plateformes

## üöÄ Task Runners - M√©thode Recommand√©e

Pour une utilisation plus simple et reproductible, utilisez les task runners :

**Recommand√© - `just` (moderne, simple):**
```bash
brew install just           # Installation (macOS)
just --list                 # Voir toutes les commandes
just setup                  # Configuration compl√®te
just run-basic              # D√©marrer sans ML
just train                  # Entra√Æner le mod√®le
just run-ml                 # D√©marrer avec ML
just health                 # V√©rifier l'√©tat du syst√®me
```

**Alternative - `make` (traditionnel, universel):**
```bash
make help                   # Voir toutes les commandes
make setup                  # Configuration compl√®te
make run-basic              # D√©marrer sans ML
make train                  # Entra√Æner le mod√®le
make run-ml                 # D√©marrer avec ML
make health                 # V√©rifier l'√©tat du syst√®me
```

üìñ **Guide complet:** Voir [TASK_RUNNERS.md](TASK_RUNNERS.md)

---

## üìä Architecture Compl√®te

```
Dataset Kaggle
    ‚Üì
Producer (Python) ‚Üí Kafka ‚Üí Spark Streaming ‚Üí MongoDB ‚Üí Tableau
                                ‚Üì
                         SparkML (Random Forest)
                                ‚Üì
                    Pr√©dictions temps r√©el
```

### Composants du Syst√®me

| Composant | Technologie | R√¥le |
|-----------|-------------|------|
| **Ingestion** | Kafka | Streaming des transactions en temps r√©el |
| **Traitement** | Spark Streaming | Traitement et transformation des donn√©es |
| **ML** | SparkML (Random Forest) | D√©tection de fraude par Machine Learning |
| **Stockage** | MongoDB | Base de donn√©es NoSQL pour persistance |
| **Visualisation** | Tableau | Dashboards et analyses visuelles |
| **Monitoring** | Dozzle, Mongo Express | Surveillance syst√®me et donn√©es |

---

## üöÄ Installation et D√©marrage

### Pr√©requis

- Docker Desktop install√© et d√©marr√©
- Python 3.9+ install√©
- Compte Kaggle (pour le dataset)
- **Recommand√©**: `just` ou `make` (task runners)
- **Alternative**:
  - **Windows**: PowerShell
  - **macOS/Linux**: Bash (inclus par d√©faut)

### Installation de `just` (Recommand√©)

```bash
# macOS
brew install just

# Linux
cargo install just

# Windows
cargo install just
# ou
scoop install just
```

> **Note**: Si vous pr√©f√©rez ne pas installer `just`, vous pouvez utiliser `make` (pr√©-install√© sur macOS/Linux) ou les scripts directs (`.sh`/`.ps1`)

### √âtape 1 : Configuration Kaggle

1. Cr√©ez un compte sur [Kaggle](https://www.kaggle.com)
2. Allez dans Settings ‚Üí API ‚Üí Create New API Token
3. Notez votre token (format : `KGAT_xxxxx...`)
4. Cr√©ez un fichier `.env` √† la racine :

```env
KAGGLE_API_TOKEN=KGAT_votre_token_ici
KAFKA_BOOTSTRAP_SERVERS=kafka:29092
KAFKA_TOPIC=fraud-detection-stream
STATE_FILE=/app/state/producer_state.db
```

### √âtape 2 : D√©marrage de l'Infrastructure

**M√©thode recommand√©e (avec task runner):**
```bash
# Avec just (recommand√©)
just start

# Avec make (alternative)
make start
```

**M√©thode manuelle (avec Docker):**
```bash
# D√©marrer tous les services Docker
docker-compose up -d

# V√©rifier que tous les containers sont UP (6 containers)
docker ps
```

**Services disponibles :**
- Kafka : `localhost:9092`
- MongoDB : `localhost:27017`
- Mongo Express : `http://localhost:8081`
- Dozzle (logs) : `http://localhost:8080`

### √âtape 3 : Installation des D√©pendances Python (Spark)

**M√©thode recommand√©e (task runner):**
```bash
# Avec just (recommand√©)
just install-deps

# Avec make (alternative)
make install-deps
```

**M√©thode manuelle (scripts directs):**
```powershell
# Windows (PowerShell)
.\setup-spark-dependencies.ps1
```
```bash
# macOS/Linux (Bash)
./setup-spark-dependencies.sh
```

**Dur√©e :** 3-5 minutes


## üîÑ Workflow Complet

### üéØ Workflow Rapide (avec Task Runners)

```bash
# Configuration initiale (une seule fois)
just setup                  # ou: make setup

# Phase 1: Accumuler des donn√©es (5-10 minutes)
just run-basic              # ou: make run-basic

# V√©rifier les donn√©es (autre terminal)
just check                  # ou: make check

# Phase 2: Entra√Æner le mod√®le (arr√™ter run-basic avec Ctrl+C d'abord)
just train                  # ou: make train

# Phase 3: Ex√©cuter avec ML
just run-ml                 # ou: make run-ml

# V√©rifier les pr√©dictions
just check-ml               # ou: make check-ml

# √âtat du syst√®me
just health                 # ou: make health
```

### üìù Workflow D√©taill√© (m√©thode manuelle)

### Phase 1 : Traitement Sans ML (Accumulation de donn√©es)

**Avec task runners (recommand√©):**
```bash
just run-basic              # ou: make run-basic
```

**Avec scripts (alternative):**
```powershell
# Windows (PowerShell)
.\start-spark-processor.ps1
```
```bash
# macOS/Linux (Bash)
./start-spark-processor.sh
```

**Laisser tourner 5-10 minutes** pour accumuler ~5000 transactions.

**V√©rification:**
```bash
# Avec task runner
just check                  # ou: make check

# Avec Python direct
python check-mongodb.py
```

### Phase 2 : Entra√Ænement du Mod√®le ML

**Avec task runners (recommand√©):**
```bash
# 1. Arr√™ter le processeur Spark (Ctrl+C dans le terminal)

# 2. Entra√Æner le mod√®le Random Forest
just train                  # ou: make train
```

**Avec scripts (alternative):**
```powershell
# Windows (PowerShell)
.\train-model.ps1
```
```bash
# macOS/Linux (Bash)
./train-model.sh
```

**Dur√©e :** 5-10 minutes

**R√©sultat attendu :**
```
üìà Dataset Statistics:
   Total transactions: 5000+
   Normal transactions: 4990+ (99.X%)
   Fraudulent transactions: 10+ (0.X%)

üå≤ Training Random Forest...
   ‚úÖ Model trained successfully!

üìà MODEL PERFORMANCE METRICS
   AUC-ROC:   0.98+
   Accuracy:  0.99+
   Precision: 0.99+
   Recall:    0.99+
   F1-Score:  0.99+

üíæ Model saved to: /app/models/fraud_detection_model
```

### Phase 3 : Pr√©dictions en Temps R√©el

**Avec task runners (recommand√©):**
```bash
just run-ml                 # ou: make run-ml
```

**Avec scripts (alternative):**
```powershell
# Windows (PowerShell)
.\start-spark-ml.ps1
```
```bash
# macOS/Linux (Bash)
./start-spark-ml.sh
```

**Le syst√®me va maintenant :**
- Lire les transactions depuis Kafka
- Faire des pr√©dictions en temps r√©el
- Ajouter `fraud_prediction` et `fraud_probability` dans MongoDB

**V√©rification des pr√©dictions:**
```bash
# Avec task runner
just check-ml               # ou: make check-ml

# Avec Python direct
python check_ml_predictions.py
```

**R√©sultat attendu :**
```
ü§ñ ML PREDICTIONS - MongoDB Statistics
================================
üìà Total transactions: 7000+
ü§ñ Transactions with ML predictions: 3500+

üìà Model Performance:
   Accuracy: 99.X%
   Precision: 100.00%
   Recall: 100.00%

üìä Confusion Matrix:
   True Positives (Fraud detected): X
   False Positives (False alarm): X
   True Negatives (Normal detected): X
   False Negatives (Fraud missed): X
```


## üìä Dataset

**Credit Card Fraud Detection** (Kaggle)
- Source : [Kaggle Dataset](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- 284,807 transactions
- 492 fraudes (0.172%)
- 31 features : Time, V1-V28 (PCA), Amount, Class

### Sch√©ma des Donn√©es

**Dans Kafka/MongoDB :**
```json
{
  "Time": 0.0,
  "V1": -1.359807,
  "V2": -0.072781,
  ...
  "V28": -0.021053,
  "Amount": 149.62,
  "Class": 0.0,
  "processed_at": "2026-01-09T14:30:45.123Z"
}
```

**Avec Pr√©dictions ML :**
```json
{
  "Time": 0.0,
  "V1": -1.359807,
  ...
  "Amount": 149.62,
  "Class": 0.0,
  "fraud_prediction": 0,
  "fraud_probability": 0.02,
  "processed_at": "2026-01-09T14:30:45.123Z"
}
```

---

## ü§ñ Machine Learning

### Algorithme : Random Forest Classifier

**Configuration :**
- Nombre d'arbres : 100
- Profondeur maximale : 10
- Features : V1-V28 + Amount (29 features)
- Normalisation : StandardScaler
- Split : 80% train / 20% test

### M√©triques de Performance

**R√©sultats typiques :**
- **AUC-ROC :** 0.98+ (excellente s√©paration des classes)
- **Accuracy :** 99%+ (tr√®s peu d'erreurs)
- **Precision :** 80-100% (peu de fausses alertes)
- **Recall :** 80-100% (peu de fraudes manqu√©es)
- **F1-Score :** 0.99+ (bon √©quilibre)

### Feature Importance

Les 10 features les plus importantes (typiquement) :
1. V14, V12, V10 (composantes PCA li√©es au comportement)
2. Amount (montant de la transaction)
3. V17, V16, V18
4. Time (moment de la transaction)

---

## üìà Monitoring et V√©rification

### Interfaces Web

| Interface | URL | Description |
|-----------|-----|-------------|
| Dozzle | `http://localhost:8080` | Logs Docker en temps r√©el |
| Mongo Express | `http://localhost:8081` | Interface MongoDB |

### Scripts de V√©rification

```bash
# V√©rifier les donn√©es dans MongoDB
python check-mongodb.py

# V√©rifier les pr√©dictions ML
python check_ml_predictions.py

# Voir les logs
docker logs producer --tail 50
docker logs spark --tail 50
docker logs mongodb --tail 50
```

### üìã Commandes Rapides par Plateforme

**Windows (PowerShell):**
```powershell
.\setup-spark-dependencies.ps1    # Installer d√©pendances
.\start-spark-processor.ps1        # D√©marrer sans ML
.\train-model.ps1                  # Entra√Æner mod√®le
.\start-spark-ml.ps1               # D√©marrer avec ML
```

**macOS/Linux (Bash):**
```bash
./setup-spark-dependencies.sh     # Installer d√©pendances
./start-spark-processor.sh         # D√©marrer sans ML
./train-model.sh                   # Entra√Æner mod√®le
./start-spark-ml.sh                # D√©marrer avec ML
```

---

## üéØ √âtat du Projet

| Composant | √âtat | Notes |
|-----------|------|-------|
| ‚úÖ Ingestion (Kafka) | **Complet** | Producer avec √©tat persistant |
| ‚úÖ Stockage (MongoDB) | **Complet** | Base NoSQL + interface web |
| ‚úÖ Traitement (Spark Streaming) | **Complet** | Traitement temps r√©el |
| ‚úÖ Machine Learning (SparkML) | **Complet** | Random Forest 99%+ accuracy |
| ‚è≥ Visualisation (Tableau) | **√Ä faire** | Prochaine √©tape |

---