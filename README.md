# üîç Syst√®me de D√©tection de Fraude en Temps R√©el

**Projet Big Data - Processus D√©cisionnel**

Syst√®me complet de d√©tection de fraude bancaire utilisant Machine Learning (3 mod√®les en ensemble) et traitement en temps r√©el avec orchestration Dagster.

---

## üìä Architecture

```
Dataset Kaggle (284K transactions)
        ‚Üì
Producer Python ‚Üí Kafka ‚Üí Spark Streaming ‚Üí MongoDB (4 collections) ‚Üí Export Excel
                             ‚Üì
                    SparkML Ensemble (3 mod√®les)
                    - Random Forest
                    - Gradient Boosting
                    - Logistic Regression
                             ‚Üì
                    Vote Majoritaire + Auto-flagging
```

### Pile Technologique

| Composant | Technologie | R√¥le |
|-----------|-------------|------|
| **Orchestration** | Dagster | Interface visuelle pour g√©rer tout le pipeline |
| **Streaming** | Apache Kafka | Ingestion temps r√©el des transactions |
| **Traitement** | Apache Spark | Traitement distribu√© et ML |
| **ML** | SparkML | 3 mod√®les en ensemble (vote majoritaire) |
| **Stockage** | MongoDB | Base NoSQL (4 collections) |
| **Visualisation** | Tableau | Dashboards et analyses |
| **Monitoring** | Dozzle, Mongo Express | Surveillance syst√®me |

---

## üöÄ D√©marrage Rapide (5 Minutes)

### Pr√©requis

- Docker Desktop install√© et d√©marr√©
- Python 3.9+ avec pip
- Compte Kaggle (pour le dataset)
- Just install√©: `brew install just` (macOS) ou [voir installation](https://github.com/casey/just#installation)

### Configuration Initiale

**1. Configuration Kaggle**

Cr√©ez un fichier `.env` √† la racine:
```env
KAGGLE_API_TOKEN=KGAT_votre_token_ici
KAFKA_BOOTSTRAP_SERVERS=kafka:29092
KAFKA_TOPIC=fraud-detection-stream
STATE_FILE=/app/state/producer_state.db
```

> **Obtenir votre token:** [Kaggle Settings](https://www.kaggle.com/settings) ‚Üí API ‚Üí Create New API Token

**2. Installation des D√©pendances**

```bash
# Cr√©er environnement virtuel Python
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
# ou: venv\Scripts\activate.ps1  # Windows

# Installer d√©pendances Python
pip install -r requirements.txt

# D√©marrer Docker et installer d√©pendances Spark
just setup
```

**3. Lancer Dagster UI**

```bash
just dagster
# Ouvre automatiquement http://localhost:3000
```

**4. Ex√©cuter le Pipeline Complet**

Dans l'interface Dagster (http://localhost:3000):
1. Cliquez sur **"Jobs"** dans le menu gauche
2. S√©lectionnez **"full_pipeline"**
3. Cliquez sur **"Launchpad"**
4. Cliquez sur **"Launch Run"**

‚úÖ **C'est tout!** Le syst√®me ex√©cute automatiquement:
- D√©marrage des services Docker
- Accumulation de donn√©es d'entra√Ænement (2 min)
- Entra√Ænement des 3 mod√®les ML (~10-15 min)
- G√©n√©ration de pr√©dictions en temps r√©el (2 min)
- Validation de la qualit√© des donn√©es
- Export vers Excel pour Tableau

---

## üé≠ Orchestration avec Dagster

### Pourquoi Dagster?

**Avant Dagster (Scripts Manuels):**
- ‚ùå 8+ commandes √† ex√©cuter manuellement
- ‚ùå Risque d'oublier une √©tape
- ‚ùå Pas de visibilit√© sur la progression
- ‚ùå Logs dispers√©s dans plusieurs terminaux
- ‚ùå Difficile de reproduire exactement

**Avec Dagster:**
- ‚úÖ Interface web professionnelle
- ‚úÖ Ex√©cution en un clic
- ‚úÖ D√©pendances automatiques (impossible d'entra√Æner sans donn√©es)
- ‚úÖ Logs centralis√©s avec m√©tadonn√©es
- ‚úÖ Progression en temps r√©el
- ‚úÖ Workflows reproductibles

### Assets Disponibles (7 √©tapes)

Le pipeline complet est compos√© de 7 assets avec d√©pendances automatiques:

```
start_docker_services
        ‚Üì
check_services
        ‚Üì
accumulate_data (2 min)
        ‚Üì
train_models (10-15 min)
        ‚Üì
run_ml_predictions (2 min)
        ‚Üì
validate_data (30s)
        ‚Üì
export_to_excel (30s)
```

**Chaque asset g√©n√®re des m√©tadonn√©es:**
- Nombre de transactions trait√©es
- Accuracy des mod√®les (>99%)
- Transactions flagg√©es (haut risque)
- Temps d'ex√©cution

### Jobs Disponibles

| Job | Description | Dur√©e | Utilisation |
|-----|-------------|-------|-------------|
| **full_pipeline** | Workflow complet de A √† Z | 15-20 min | Premi√®re fois, d√©mo compl√®te |
| **accumulate_data** | Collecter donn√©es d'entra√Ænement | 2-3 min | Besoin de plus de donn√©es |
| **train_models** | R√©entra√Æner les 3 mod√®les | 10-15 min | Apr√®s ajout de donn√©es |
| **run_ml_predictions** | G√©n√©rer pr√©dictions temps r√©el | 2-3 min | Tester les mod√®les |
| **validate_data** | V√©rifier qualit√© et accuracy | 30s | Health check rapide |

### Interfaces Web

Une fois Dagster lanc√© (`just dagster`):

| Interface | URL | Description |
|-----------|-----|-------------|
| **Dagster UI** | http://localhost:3000 | Orchestration principale |
| **Mongo Express** | http://localhost:8081 | Navigateur de donn√©es MongoDB |
| **Dozzle** | http://localhost:8080 | Logs Docker temps r√©el |

---

## ü§ñ Machine Learning - Approche Ensemble

### Dataset: Credit Card Fraud Detection (Kaggle)

- **Source:** [Kaggle Dataset](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- **Taille:** 284,807 transactions
- **Fraudes:** 492 cas (0.172% - tr√®s d√©s√©quilibr√©)
- **Features:** 31 colonnes
  - `Time`: Secondes depuis la premi√®re transaction
  - `V1-V28`: 28 composantes PCA (anonymisation)
  - `Amount`: Montant de la transaction
  - `Class`: 0 (normal) ou 1 (fraude)

### 3 Mod√®les Compl√©mentaires

**1. Random Forest Classifier**
- 100 arbres de d√©cision
- Profondeur maximale: 10
- Excellent pour capturer les interactions non-lin√©aires

**2. Gradient Boosting Trees**
- 50 it√©rations
- Profondeur maximale: 5
- Tr√®s performant sur classes d√©s√©quilibr√©es

**3. Logistic Regression**
- 100 it√©rations
- R√©gularisation: 0.01
- Baseline interpr√©table

### Strat√©gie Ensemble: Vote Majoritaire

```python
# Pour chaque transaction:
vote_rf = model_random_forest.predict(transaction)
vote_gb = model_gradient_boosting.predict(transaction)
vote_lr = model_logistic_regression.predict(transaction)

# D√©cision finale
final_prediction = majority_vote(vote_rf, vote_gb, vote_lr)
confidence = average(prob_rf, prob_gb, prob_lr)

# Auto-flagging (action imm√©diate requise)
if confidence > 0.80 or (vote_rf == vote_gb == vote_lr == 1):
    flag_transaction(transaction)
```

**Avantages:**
- **Robustesse:** Un mod√®le seul peut se tromper, 3 mod√®les d'accord = haute confiance
- **R√©duction faux positifs:** Unanimit√© ou haute probabilit√© requise pour flagging
- **Performance:** Accuracy >99%, Precision >90%, Recall >85%

### M√©triques de Performance

**R√©sultats typiques apr√®s entra√Ænement:**
- **AUC-ROC:** 0.98+ (excellente s√©paration des classes)
- **Accuracy:** 99%+ (tr√®s peu d'erreurs)
- **Precision:** 90-100% (peu de fausses alarmes)
- **Recall:** 85-95% (peu de fraudes manqu√©es)
- **F1-Score:** 0.95+ (bon √©quilibre)

---

## üóÑÔ∏è Base de Donn√©es MongoDB

### Structure: 4 Collections

**1. `transactions`** - Toutes les transactions brutes
```json
{
  "Time": 0.0,
  "V1": -1.359, "V2": -0.072, ..., "V28": -0.021,
  "Amount": 149.62,
  "Class": 0.0,
  "processed_at": "2026-01-10T14:30:45Z"
}
```

**2. `model_predictions`** - Pr√©dictions individuelles par mod√®le
```json
{
  "transaction_id": "...",
  "model_name": "random_forest",
  "prediction": 0,
  "probability": 0.02,
  "timestamp": "2026-01-10T14:30:46Z"
}
```

**3. `ensemble_results`** - D√©cisions finales (vote majoritaire)
```json
{
  "transaction_id": "...",
  "final_prediction": 0,
  "confidence_score": 0.03,
  "model_agreement": true,
  "votes": {"rf": 0, "gb": 0, "lr": 0},
  "timestamp": "2026-01-10T14:30:47Z"
}
```

**4. `flagged_transactions`** - Cas √† haut risque
```json
{
  "transaction_id": "...",
  "reason": "all_models_agree",
  "confidence": 0.95,
  "amount": 5000.00,
  "flagged_at": "2026-01-10T14:30:47Z",
  "action_required": true
}
```

**Pourquoi 4 collections?**
- **Tra√ßabilit√©:** Audit complet de chaque d√©cision
- **Analytics:** Analyser performance de chaque mod√®le
- **Business Intelligence:** Dashboards Tableau d√©taill√©s
- **Actions:** Isoler les cas critiques (flagged)

---

## üìà Visualisation et D√©cisions

### Export vers Tableau

Le syst√®me g√©n√®re automatiquement 4 fichiers Excel (dossier `exports/`):
- `transactions.xlsx` - Toutes les transactions
- `model_predictions.xlsx` - Pr√©dictions par mod√®le
- `ensemble_results.xlsx` - D√©cisions finales
- `flagged_transactions.xlsx` - Cas critiques

### D√©cisions Business Support√©es

**1. Blocage Temps R√©el**
- Si transaction flagg√©e ‚Üí bloquer imm√©diatement la carte
- R√©duction pertes financi√®res
- Notification client pour v√©rification

**2. Analyse des Patterns**
- Identifier nouvelles techniques de fraude
- Montants moyens des fraudes
- Heures/jours √† risque √©lev√©
- Localisation g√©ographique (si disponible)

**3. Optimisation Mod√®les**
- Comparer performance des 3 mod√®les
- Identifier faux positifs/n√©gatifs
- Ajuster seuils de confiance
- R√©entra√Ænement p√©riodique

**4. Reporting et Conformit√©**
- Historique complet pour audit
- Taux de d√©tection par p√©riode
- Co√ªts √©vit√©s (fraudes d√©tect√©es)
- SLA: latence de d√©tection

üìä **Voir [CHARTS.md](docs/CHARTS.md)** pour le guide complet des visualisations Tableau √† cr√©er.

---

## üõ†Ô∏è Commandes Utiles

### Infrastructure

```bash
just setup          # Configuration initiale compl√®te
just start          # D√©marrer Docker services
just stop           # Arr√™ter Docker services
just restart        # Red√©marrer services
just health         # V√©rifier √©tat du syst√®me
```

### Dagster

```bash
just dagster        # Lancer Dagster UI (http://localhost:3000)
```

Tous les workflows (accumulation, entra√Ænement, pr√©dictions, validation, export) se font maintenant via l'interface Dagster UI.

### Monitoring

```bash
just logs           # Voir logs de tous les services
just log <service>  # Logs d'un service sp√©cifique
just ui-mongo       # Ouvrir Mongo Express
just ui-logs        # Ouvrir Dozzle
```

### Maintenance

```bash
just clean             # Nettoyer toutes les donn√©es (reset complet)
just clean-checkpoint  # Fixer erreurs Spark
just reset-producer    # Red√©marrer producer depuis le d√©but
```

### Debug

```bash
just shell-spark    # Shell dans container Spark
just shell-mongo    # Shell MongoDB
just disk-usage     # Utilisation disque Docker
```

---

## üìö Documentation

| Document | Contenu |
|----------|---------|
| **README.md** (ce fichier) | Vue d'ensemble, architecture, d√©marrage |
| [**INSTRUCTIONS.md**](docs/INSTRUCTIONS.md) | Guide pas-√†-pas pour pr√©sentation en classe |
| [**CHARTS.md**](docs/CHARTS.md) | Visualisations Tableau et d√©cisions business |

---

## üéØ Workflow Typique

### Premi√®re Utilisation

```bash
# 1. Setup (une seule fois)
just setup

# 2. Lancer Dagster
just dagster

# 3. Dans Dagster UI (http://localhost:3000)
#    Jobs ‚Üí full_pipeline ‚Üí Launch Run

# 4. Attendre 15-20 minutes (tout est automatique)

# 5. R√©sultats dans exports/ (Excel pour Tableau)
```

### R√©entra√Ænement avec Plus de Donn√©es

```bash
# Dagster UI: Jobs ‚Üí accumulate_data ‚Üí Launch Run
# Attendre 2-3 minutes pour +1000-1500 transactions

# Dagster UI: Jobs ‚Üí train_models ‚Üí Launch Run
# Attendre 10-15 minutes

# Dagster UI: Jobs ‚Üí run_ml_predictions ‚Üí Launch Run
# V√©rifier les nouvelles m√©triques
```

### Validation Rapide

```bash
# Dagster UI: Jobs ‚Üí validate_data ‚Üí Launch Run
# 30 secondes pour v√©rifier:
#   - Qualit√© des donn√©es
#   - Accuracy des mod√®les
#   - Distribution fraude/normal
#   - Flagged transactions count
```

---

## üèÜ Points Cl√©s pour Pr√©sentation

### Techniquement

- **Streaming temps r√©el:** Kafka + Spark (pas de batch)
- **ML distribu√©:** SparkML sur cluster (scalable)
- **Ensemble learning:** 3 mod√®les = robustesse
- **NoSQL flexible:** MongoDB 4 collections pour tra√ßabilit√©
- **Orchestration moderne:** Dagster pour reproductibilit√©

### Business

- **D√©tection imm√©diate:** <2 secondes bout-en-bout
- **High accuracy:** >99% de pr√©cision
- **R√©duction pertes:** Fraudes bloqu√©es en temps r√©el
- **D√©cisions data-driven:** Dashboards Tableau pour insights
- **Audit complet:** Historique MongoDB de chaque transaction

### D√©monstration

1. **Montrer l'architecture** (sch√©ma ci-dessus)
2. **Lancer Dagster UI** ‚Üí visualiser le graphe d'assets
3. **Ex√©cuter full_pipeline** ‚Üí progression temps r√©el
4. **Ouvrir Mongo Express** ‚Üí 4 collections avec donn√©es
5. **Montrer exports/** ‚Üí fichiers Excel pour Tableau
6. **Expliquer d√©cisions business** support√©es

---

## üìù Licence & Cr√©dits

**Projet acad√©mique** - Processus D√©cisionnel Big Data
**Dataset:** [Credit Card Fraud Detection (Kaggle)](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
**Technologies:** Apache Kafka, Apache Spark, MongoDB, Dagster, Python, Docker

---

**üöÄ Pr√™t √† d√©marrer? Lancez `just setup` puis `just dagster`!**
